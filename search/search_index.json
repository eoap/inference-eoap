{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Introduction","text":"<p>Platforms for the exploitation of Earth Observation (EO) data have been developed by public and private companies in order to foster the usage of EO data and expand the market of Earth Observation-derived information. A fundamental principle of the platform operations concept is to move the EO data processing service\u2019s user to the data and tools, as opposed to downloading, replicating, and exploiting data \u2018at home\u2019. In this scope, previous OGC activities initiated the development of an architecture to allow the ad-hoc deployment and execution of applications close to the physical location of the source data with the goal to minimize data transfer between data repositories and application processes.</p> <p>The OGC published the Best Practice for Earth Observation Application Package, a document defining the Best Practice to package and deploy Earth Observation Applications in an Exploitation Platform. The document is targeting the implementation, packaging and deployment of EO Applications in support of collaborative work processes between developers and platform owners.</p> <p>The Best Practice includes recommendations for the application design patterns, package encoding, container and data interfaces for data stage-in and stage-out strategies focusing on three main viewpoints: Application, Package and Platform.</p> <p>The focus of this documentation set is the inference using an ONNX model where the application package wraps the inference function using ONNX python runtime.</p>"},{"location":"#the-model","title":"The model","text":"<p>The model was trained using a Sequential Convolutional Neural Network (CNN) with Keras based on the benchmark dataset EuroSAT.</p> <p>The tile based classification application takes a trained model in the ONNX format and does the inference on Sentinel-2 Level-1C data.</p>"},{"location":"app/tile-based-classification/","title":"Tile based classification","text":"<p>The tile based classification application takes a trained model in the ONNX format and does the inference on Sentinel-2 Level-1C data.</p> <p>The model was trained using a Sequential Convolutional Neural Network (CNN) with Keras based on the benchmark dataset EuroSAT. </p>"},{"location":"app/tile-based-classification/#training-data","title":"Training Data","text":"<p>The model is trained on the EuroSAT benchmark dataset which is based on Sentinel-2 satellite images and consists of a total of 27,000 labeled and geo-referenced images. </p> <p>The dataset provides information on the following ten land cover / land use classes:</p> <ul> <li>Annual Crop</li> <li>Forest</li> <li>Herbaceous Vegetation</li> <li>Highway</li> <li>Industrial</li> <li>Pasture</li> <li>Permanent Crop</li> <li>Residential</li> <li>River</li> <li>Sea Lake</li> </ul> <p>The benchmark dataset can be used to detect land cover/land use changes. </p>"},{"location":"app/tile-based-classification/#inference","title":"Inference","text":"<p>The inference is the process where the learned capabilities of a pre-trained model are put into practice and applied to a Sentinel-2 Level-1C acquisition.</p> <p>This application foresees using Sentinel-2 Level-1C data converted to COG and structured as a STAC Catalog and Item.</p> <p>There is a pre-processing step to stage and convert to STAC/COG a Sentinel-2 Level-1C acquisition then used for the inference process.</p> <p>The inference step loads the pre-trained model and executes the inference process, which 'infers' land cover classes.</p>"},{"location":"app/inference/app/","title":"Description","text":""},{"location":"app/inference/app/#inference","title":"Inference","text":""},{"location":"app/inference/app/#step-purpose","title":"Step purpose","text":"<p>Purpose: apply the inference function loaded from an ONNX model to a Sentinel-2 Level-1C staged and converted to COG. The output is a tile based classification encoded as a STAC Catalog with a STAC Item.</p>"},{"location":"app/inference/app/#code","title":"Code","text":"<p>The <code>predict.py</code> script is a command-line tool designed for performing inference on Sentinel-2 Level-1C product assets using a pre-trained ONNX model. The output is a classified image saved as a GeoTIFF file and a corresponding STAC Item with the classification results. </p> <p>This process involves stacking bands, dividing the image into tiles, running inference, and saving the results. </p> <p>The script uses Python libraries such as <code>pystac</code>, <code>rasterio</code>, <code>onnx</code>, <code>onnxruntime</code>, <code>numpy</code>, <code>click</code>, and <code>loguru</code>.</p>"},{"location":"app/inference/app/#functionalities-and-flow","title":"Functionalities and Flow","text":"<p>Importing Required Libraries:</p> <ul> <li><code>os</code>: For interacting with the operating system (e.g., file paths).</li> <li><code>shutil.move</code>: For moving files.</li> <li><code>numpy</code>: For numerical operations.</li> <li><code>onnx</code>: For working with ONNX models.</li> <li><code>onnxruntime</code>: For running inference using ONNX models.</li> <li><code>rasterio</code>: For reading and writing geospatial raster data.</li> <li><code>pystac</code>: For working with STAC items and catalogs.</li> <li><code>click</code>: For creating command-line interfaces.</li> <li><code>loguru</code>: For logging.</li> </ul> <p>Helper Functions:</p> <ul> <li><code>sliding(shape, window_size, step_size=None, fixed=True)</code>:</li> </ul> <p>Generates a list of windows (tiles) for sliding over the input image. Each window is defined by its coordinates (x, y, width, height). infer(model_path: str, s2_arr: np.ndarray) -&gt; np.ndarray: Loads the ONNX model and checks its structure. Divides the input image into windows and runs inference on each window. Assembles the prediction results into a classified image.</p> <ul> <li><code>read_image(src_path: str) -&gt; np.ndarray</code>:</li> </ul> <p>Reads the raster data from the specified file path and returns it as a numpy array.</p> <ul> <li><code>stack(item: pystac.Item) -&gt; np.ndarray</code>:</li> </ul> <p>Stacks the bands of the input STAC Item into a single numpy array. Each band is resized and appended to the list, which is then stacked and transposed.</p> <ul> <li><code>get_geocoding(asset_href: str) -&gt; (rasterio.crs.CRS, Affine)</code>:</li> </ul> <p>Retrieves the coordinate reference system (CRS) and transformation matrix from the specified asset. save_prediction(data: np.ndarray, output_href: str, crs: rasterio.crs.CRS, transform: Affine): Saves the classified image data to a GeoTIFF file with specified CRS and transform. Builds overviews for the output GeoTIFF file.</p> <ul> <li><code>to_stac(geotiff_path: str, item: pystac.Item) -&gt; pystac.Item</code>:</li> </ul> <p>Creates a new STAC Item for the classified GeoTIFF file. Uses rio_stac to generate the STAC Item with the necessary metadata.</p> <p>Main Function: <code>predict</code></p> <ul> <li>Reading the STAC Item:</li> </ul> <p>Reads the STAC Item from the provided URL or path.</p> <ul> <li>Stacking Bands:</li> </ul> <p>Stacks the bands of the STAC Item into a single numpy array.</p> <ul> <li>Running Inference:</li> </ul> <p>Runs inference using the pre-trained ONNX model on the stacked array. Divides the image into windows and processes each batch.</p> <ul> <li>Saving the Prediction:</li> </ul> <p>Saves the prediction result as a GeoTIFF file. Retrieves the geocoding information (CRS and transform) from one of the bands.</p> <ul> <li>Creating a New STAC Item:</li> </ul> <p>Creates a new STAC Item for the classified image. Adds the new STAC Item to a catalog and saves it as a self-contained STAC Catalog.</p> <ul> <li>Moving Output File:</li> </ul> <p>Moves the classified GeoTIFF file to the output directory.</p>"},{"location":"app/inference/app/#script-execution","title":"Script Execution","text":"<p>The script is executable as a command-line tool as its usage is:</p> <pre><code>Usage: python -m app.app [OPTIONS]\n\n  Inference on a STAC Item asset with a trained model\n\nOptions:\n  --input-item TEXT  STAC Item URL or staged STAC catalog  [required]\n  --help             Show this message and exit.\n</code></pre>"},{"location":"app/inference/app/#listing","title":"Listing","text":"<p>The Python code is provided here:</p> tile-based-classification/command-line-tools/inference/app.py<pre><code>import os\nfrom shutil import move\nimport numpy as np\nimport onnx\nimport onnxruntime as ort\nimport rasterio\nimport pystac\nimport click\nfrom loguru import logger\nfrom rasterio.enums import Resampling\nfrom rio_stac.stac import create_stac_item\n\n\n\ndef sliding(shape, window_size, step_size=None, fixed=True):\n\n    h, w = shape\n    if step_size:\n        h_step = step_size\n        w_step = step_size\n    else:\n        h_step = window_size\n        w_step = window_size\n\n    h_wind = window_size\n    w_wind = window_size\n    windows = []\n    for y in range(0, h, h_step):\n        for x in range(0, w, w_step):\n            h_min = min(h_wind, h - y)\n            w_min = min(w_wind, w - x)\n            if fixed:\n                if h_min &lt; h_wind or w_min &lt; w_wind:\n                    continue\n            window = (x, y, w_min, h_min)\n            windows.append(window)\n\n    return windows\n\n\ndef infer(model_path, s2_arr):\n    onnx_model = onnx.load(model_path)\n\n    # Check the model\n    onnx.checker.check_model(onnx_model)\n    logger.info(f\"The model {model_path} is structured correctly.\")\n    sess = ort.InferenceSession(model_path)\n    input_name = sess.get_inputs()[0].name\n    output_name = sess.get_outputs()[0].name\n\n    logger.info(\"Divide all image into windows for inference step\")\n\n    target_shape = (s2_arr.shape[0], s2_arr.shape[1])\n    logger.debug(f\"Target shape: {target_shape}\")\n\n    windows = sliding(target_shape, 64, fixed=True)\n\n    windows_ = iter(windows)\n    windows_class = iter(windows)\n\n    batch_size = 10\n    total_chips = len(windows)\n    num_steps = int(total_chips / batch_size)\n\n    # Initialize the classification result array\n    img_classes = np.zeros((s2_arr.shape[0], s2_arr.shape[1]), dtype=np.uint8)\n\n    predictions = []\n\n    logger.info(\"Start the inference step\")\n    for b in range(num_steps):\n        logger.info(f\"Processing batch {b+1}/{num_steps}\")\n        chips = np.empty((batch_size, 64, 64, 13))\n        for k in range(batch_size):\n            ymin, xmin, xmax, ymax = next(windows_)\n            chips[k] = s2_arr[\n                xmin : xmin + xmax, ymin : ymin + ymax, :\n            ]  # Adapt based on how your data is structured\n\n        # Run prediction with ONNX\n        preds = sess.run([output_name], {input_name: chips.astype(np.float32)})[0]\n        predictions.append(np.argmax(preds, axis=-1))\n\n        # Classify the image parts\n        for i in range(batch_size):\n            ymin_cl, xmin_cl, xmax_cl, ymax_cl = next(windows_class)\n            img_classes[xmin_cl : xmin_cl + xmax_cl, ymin_cl : ymin_cl + ymax_cl] = (\n                predictions[b][i]\n            )\n\n    return img_classes\n\n\ndef read_image(src_path):\n    with rasterio.open(src_path) as src:\n        data = src.read()\n\n    return data\n\n\ndef stack(item):\n\n    bands = [key for key, asset in item.get_assets().items() if \"data\" in asset.roles]\n\n    # Prepare array to hold all bands\n    all_bands = []\n\n    # Process each band\n    for band_key in bands:\n        asset = item.assets.get(band_key)\n        if asset is not None:\n            logger.info(band_key, asset.title)\n            # Resize and append to list\n            band_data = read_image(asset.get_absolute_href())\n            all_bands.append(band_data)\n        else:\n            logger.info(f\"Band {band_key} not found in assets.\")\n\n    # Stack all bands into a single numpy array\n    all_bands_array = np.stack(all_bands)\n    all_bands_array_t = np.transpose(all_bands_array, (2, 3, 1, 0))\n\n    del all_bands_array\n    # Squeeze out the singleton dimension (the second last one in this case)\n    stacked_array = np.squeeze(all_bands_array_t, axis=2)\n    del all_bands_array_t\n\n    return stacked_array\n\n\ndef get_geocoding(asset_href):\n\n    with rasterio.open(asset_href) as dataset:\n        crs = dataset.crs\n        transform = dataset.transform\n\n    return crs, transform\n\n\ndef save_prediction(data, output_href, crs, transform):\n\n    with rasterio.open(\n        output_href,\n        \"w\",\n        driver=\"GTiff\",\n        height=data.shape[0],\n        width=data.shape[1],\n        count=1,\n        dtype=data.dtype,\n        crs=crs,\n        transform=transform,\n        tiled=True,\n        blockxsize=256,\n        blockysize=256,\n        compress=\"deflate\",\n        interleave=\"band\",\n    ) as dst:\n        dst.write(data, 1)\n        dst.build_overviews([2, 4, 8, 16], Resampling.nearest)\n        dst.update_tags(ns=\"rio_overview\", resampling=\"nearest\")\n\n\ndef to_stac(geotiff_path, item):\n\n    result_item = create_stac_item(\n        id=f\"{item.id}-classification\",\n        source=geotiff_path,\n        asset_name=\"classification\",\n        asset_roles=[\"data\"],\n        with_proj=True,\n        with_raster=True,\n        properties={},\n    )\n\n    return result_item\n\n\n@click.command(\n    short_help=\"Inference - tile-based classification with ONNX model\",\n    help=\"Inference on a STAC Item asset with a trained model\",\n)\n@click.option(\n    \"--input-item\",\n    \"item_url\",\n    help=\"STAC Item URL or staged STAC catalog\",\n    required=True,\n)\ndef predict(item_url):\n\n    if os.path.isdir(item_url):\n        catalog = pystac.read_file(os.path.join(item_url, \"catalog.json\"))\n        item = next(catalog.get_items())\n    else:\n        item = pystac.read_file(item_url)\n\n    logger.info(f\"Read {item.get_self_href()} and stack bands for {item.id}\")\n\n    s2_arr = stack(item)\n    logger.debug(f\"Stacked array shape: {s2_arr.shape}\")\n\n    prediction = infer(\n        model_path=os.path.join(\n            os.path.dirname(os.path.abspath(__file__)),\n            \"model\",\n            \"sentinel2_classification_trained_model_e50_9190.onnx\",\n        ),\n        s2_arr=s2_arr,\n    )\n\n    logger.debug(f\"Prediction shape: {prediction.shape}\")\n\n    crs, transform = get_geocoding(item.assets.get(\"red\").get_absolute_href())\n\n    save_prediction(prediction, \"classification.tif\", crs, transform)\n\n    out_item = to_stac(\"classification.tif\", item)\n\n    logger.info(f\"Creating a STAC Catalog for the classification result\")\n    cat = pystac.Catalog(\n        id=\"catalog\", description=\"classification result\", title=\"classification result\"\n    )\n    cat.add_items([out_item])\n\n    cat.normalize_and_save(\n        root_href=\"./\", catalog_type=pystac.CatalogType.SELF_CONTAINED\n    )\n    move(\"classification.tif\", os.path.join(out_item.id, \"classification.tif\"))\n    logger.info(\"Done!\")\n\n\nif __name__ == \"__main__\":\n    predict()\n</code></pre>"},{"location":"app/sen2cog/app/","title":"Convert to COG","text":""},{"location":"app/sen2cog/app/#stages-sentinel-2-level-1c-conversion-to-cog","title":"Stages Sentinel-2 Level-1C conversion to COG","text":""},{"location":"app/sen2cog/app/#step-purpose","title":"Step purpose","text":"<p>Purpose: convert the Sentinel-2 Level-1 jp2 assets to COG and resample the 20m and 60m resolution bands to 10m</p>"},{"location":"app/sen2cog/app/#code","title":"Code","text":"<p>The <code>to_cog.py</code> script is a command-line tool designed to convert Sentinel-2 Level-1C product assets to Cloud Optimized GeoTIFF (COG) format. The output is a STAC Item with COG assets.</p> <p>This process involves reading a STAC Catalog, resizing and converting assets, and creating a new STAC Item with the converted assets. </p> <p>The script uses Python libraries such as <code>pystac</code>, <code>rasterio</code>, <code>click</code>, and <code>loguru</code>.</p>"},{"location":"app/sen2cog/app/#functionalities-and-flow","title":"Functionalities and Flow","text":"<p>Importing Required Libraries:</p> <ul> <li><code>os</code>: For interacting with the operating system (e.g., file paths).</li> <li><code>rasterio</code>: For reading and writing geospatial raster data.</li> <li><code>pystac</code>: For working with STAC items and catalogs.</li> <li><code>click</code>: For creating command-line interfaces.</li> <li><code>loguru</code>: For logging.</li> <li><code>shutil.move</code>: For moving files.</li> </ul> <p>Helper Function:</p> <ul> <li><code>resize_and_convert_to_cog(src_path: str, output_path: str, target_resolution=(10, 10))</code>:</li> </ul> <p>Resizes the image to the target resolution and converts it to COG format. Opens the source file and calculates the new shape based on the target resolution. Reads and resamples the data using bilinear resampling. Updates the metadata for the transformed dataset and writes the data to a COG file with LZW compression.</p> <p>Command-line Interface:</p> <p>Defined using <code>click</code> with an option for the input STAC Catalog URL.</p> <p>Options:</p> <ul> <li><code>--input-catalog</code>: URL or path of the STAC Catalog containing a Sentinel-2 Level-1C item (required).</li> </ul> <p>Here is an overview of the script's functionality:</p> <p>Reading the STAC Catalog:</p> <ul> <li>Reads the STAC Catalog from the provided URL or path.</li> <li>Retrieves the first item from the catalog.</li> </ul> <p>Setting Up Output Directory:</p> <ul> <li>Creates a directory named after the item ID if it doesn't exist.</li> </ul> <p>Creating a New STAC Item:</p> <ul> <li>Creates a new STAC Item with the same properties as the original item.</li> <li>Adds the EO extension to the new item.</li> </ul> <p>Converting Assets to COG:</p> <ul> <li>Iterates through the assets of the original item and converts each asset with the role \"data\" to COG format.</li> <li>Resizes and converts the asset using resize_and_convert_to_cog.</li> <li>Creates a new asset for the COG file and adds it to the new item.</li> <li>Moves the COG file to the output directory.</li> </ul> <p>Creating a New STAC Catalog:</p> <ul> <li>Creates a new STAC Catalog and adds the new item to it.</li> <li>Normalizes and saves the catalog as a self-contained STAC Catalog.</li> </ul>"},{"location":"app/sen2cog/app/#script-execution","title":"Script Execution","text":"<p>The script is executable as a command-line tool as its usage is:</p> <pre><code>Usage: python -m app.app [OPTIONS]\n\n  Convert a Sentinel-2 Level-1C product to COG format. The output is a STAC\n  Item with COG assets.\n\nOptions:\n  --input-catalog TEXT  STAC Catalog with an Sentinel-2 Level-1C item\n                        [required]\n  --help                Show this message and exit.\n</code></pre>"},{"location":"app/sen2cog/app/#listing","title":"Listing","text":"<p>The Python code is provided here:</p> tile-based-classification/command-line-tools/sen2cog/app.py<pre><code>import os\nimport rasterio\nimport pystac\nimport click\nfrom shutil import move\nfrom loguru import logger\nfrom rasterio.enums import Resampling\nfrom pystac.extensions.eo import EOExtension\n\n\ndef resize_and_convert_to_cog(src_path, output_path, target_resolution=(10, 10)):\n    with rasterio.open(src_path) as src:\n        # Calculate the new shape based on the target resolution\n        scale_x = src.width * (src.res[0] / target_resolution[0])\n        scale_y = src.height * (src.res[1] / target_resolution[1])\n        logger.info(f\"Resizing image to {scale_x}x{scale_y}\")\n        # Read and resample data\n        data = src.read(\n            out_shape=(src.count, int(scale_y), int(scale_x)),\n            resampling=Resampling.bilinear,\n        )\n\n        # Update the metadata for the transformed dataset\n        transform = src.transform * src.transform.scale(\n            (src.width / data.shape[-1]), (src.height / data.shape[-2])\n        )\n        profile = src.profile\n        profile.update(\n            {\n                \"driver\": \"COG\",\n                \"dtype\": data.dtype,\n                \"height\": data.shape[1],\n                \"width\": data.shape[2],\n                \"transform\": transform,\n                \"compress\": \"LZW\",\n                \"interleave\": \"pixel\",\n            }\n        )\n\n        # Write data directly to a COG file\n        with rasterio.open(output_path, \"w\", **profile) as dst:\n            dst.write(data)\n\n@click.command(\n    short_help=\"Convert a Sentinel-2 to COG\",\n    help=\"Convert a Sentinel-2 Level-1C product to COG format. The output is a STAC Item with COG assets.\",\n)\n@click.option(\n    \"--input-catalog\",\n    \"catalog_url\",\n    help=\"STAC Catalog with an Sentinel-2 Level-1C item\",\n    required=True,\n)\ndef to_cog(catalog_url):\n\n    if os.path.isdir(catalog_url):\n        catalog = pystac.read_file(os.path.join(catalog_url, \"catalog.json\"))\n        item = next(catalog.get_items())\n    else:\n        item = pystac.read_file(catalog_url)\n\n    os.makedirs(item.id, exist_ok=True)\n    item_out = pystac.Item(\n        id=f\"{item.id}\",\n        geometry=item.geometry,\n        bbox=item.bbox,\n        datetime=item.datetime,\n        properties=item.properties,\n    )\n    eo = EOExtension.ext(item_out, add_if_missing=True)\n\n    logger.info(f\"Read {item.get_self_href()} and stack bands for {item.id}\")\n\n    # loop through the assets and convert them to COG\n    for key, asset in item.get_assets().items():\n        logger.info(f\"Converting asset {key} to COG\")\n        if \"data\" not in asset.roles:\n            continue\n\n        output_cog_file_path = f\"{key}.tif\"\n        resize_and_convert_to_cog(\n            asset.get_absolute_href(), output_cog_file_path, target_resolution=(10, 10)\n        )\n        logger.info(f\"COG file created: {output_cog_file_path}\")\n\n        # create a new asset for the COG file\n        cog_asset = pystac.Asset(\n            href=output_cog_file_path, media_type=pystac.MediaType.COG, roles=[\"data\"]\n        )\n        src_eo_asset = EOExtension.ext(asset)\n\n        item_out.add_asset(key, asset=cog_asset)\n        # add eo extension to the asset\n\n        logger.info(f\"Adding EO extension to asset {key}\")\n        eo_on_asset = EOExtension.ext(item_out.assets[key])\n        eo_on_asset.apply(src_eo_asset.bands)\n\n        move(output_cog_file_path, os.path.join(item.id, output_cog_file_path))\n\n    cat = pystac.Catalog(\n        id=\"catalog\", description=\"sen2cog result\", title=\"sen2cog result\"\n    )\n    cat.add_items([item_out])\n\n    cat.normalize_and_save(\n        root_href=\"./\", catalog_type=pystac.CatalogType.SELF_CONTAINED\n    )\n\n    print(item_out.to_dict())\n\nif __name__ == \"__main__\":\n    to_cog()\n</code></pre>"},{"location":"app/stage-in/app/","title":"Stage-in","text":""},{"location":"app/stage-in/app/#sentinel-2-level-1c-stage-in","title":"Sentinel-2 Level-1C stage-in","text":""},{"location":"app/stage-in/app/#step-purpose","title":"Step purpose","text":"<p>Purpose: While there are many options to consume Sentinel-2 Level-2A in a Cloud native processing approach, the Level-1C data must instead be staged from the Copernicus Data Space Ecosystem. The output is a STAC Catalog referencing a local STAC Item with the Sentinel-2 Level-1C files (assets) available in the local filesystem</p>"},{"location":"app/stage-in/app/#code","title":"Code","text":"<p>The <code>stage-in.py</code> script is a command-line tool designed to stage Sentinel-2 Level-1C products. It downloads, extracts, and creates STAC (SpatioTemporal Asset Catalog) items from a provided STAC item URL. This process involves handling asset URLs, downloading and extracting files, and generating a catalog. </p> <p>The script leverages Python libraries such as <code>pystac</code>, <code>requests</code>, <code>click</code>, <code>loguru</code>, and <code>stactools.sentinel2.stac</code>.</p>"},{"location":"app/stage-in/app/#functionalities-and-flow","title":"Functionalities and Flow","text":"<p>Importing Required Libraries:</p> <ul> <li><code>os</code>: For interacting with the operating system (e.g., file paths).</li> <li><code>zipfile</code>: For handling zip file extraction.</li> <li><code>click</code>: For creating command-line interfaces.</li> <li><code>pystac</code>: For working with STAC items and catalogs.</li> <li><code>requests</code>: For making HTTP requests.</li> <li><code>loguru</code>: For logging.</li> <li><code>stactools.sentinel2.stac</code>: For creating STAC items specific to Sentinel-2 products.</li> </ul> <p>Helper Functions:</p> <ul> <li><code>get_asset_href(item: pystac.Item, asset_key: str) -&gt; str</code>:</li> </ul> <p>Retrieves the asset URL of a STAC Item given its asset key. Replaces \"catalogue\" with \"zipper\" in the asset's href to get the correct download URL.</p> <ul> <li><code>download_and_extract_file(item: pystac.Item, access_token: str) -&gt; str</code>:</li> </ul> <p>Downloads and extracts the asset file from a STAC Item using an access token. Sets up headers for authorization and makes a request to download the file. Saves the downloaded file as \"product.zip\" and extracts it. Returns the path to the extracted files.</p> <p>Here is an overview of the script's functionality:</p> <p>Staging Process:</p> <ul> <li>Logs the staging process.</li> <li>Reads the STAC Item from the provided URL using <code>pystac</code>.</li> <li>Retrieves the access token from the environment variable <code>CDSE_ACCESS_TOKEN</code>.</li> <li>Downloads and extracts the file using <code>download_and_extract_file</code>.</li> </ul> <p>Creating STAC Item:</p> <ul> <li>Uses create_item from <code>stactools.sentinel2.stac</code> to create a STAC Item from the extracted files.</li> <li>Sets the self-href for the STAC Item and saves it to a JSON file.</li> </ul> <p>Creating STAC Catalog:</p> <ul> <li>Creates a STAC Catalog, adds the STAC Item, and normalizes hrefs.</li> <li>Saves the catalog as a self-contained STAC Catalog.</li> </ul>"},{"location":"app/stage-in/app/#script-execution","title":"Script Execution","text":"<p>The script is executable as a command-line tool as its usage is:</p> <pre><code>Usage: python -m app.app [OPTIONS]\n\n  Stage a Sentinel-2 Level-1C product\n\nOptions:\n  --input-item TEXT  Sentinel-2 Level-1C CDSE STAC Item URL  [required]\n  --help             Show this message and exit.\n</code></pre>"},{"location":"app/stage-in/app/#listing","title":"Listing","text":"<p>The Python code is provided here:</p> tile-based-classification/command-line-tools/stage-in/app.py<pre><code>import os\nimport zipfile\nimport click\nimport pystac \nimport requests\nfrom stactools.sentinel2.stac import create_item\nfrom loguru import logger\n\ndef get_asset_href(item, asset_key):\n    \"\"\"Returns the asset of a STAC Item defined with its asset key\"\"\"\n    for key, asset in item.get_assets().items():\n        if key in [asset_key]:    \n            return asset.href.replace(\"catalogue\", \"zipper\")\n\ndef download_and_extract_file(item: pystac.Item, access_token: str):\n    \"\"\"Downloads and extracts the asset file from a STAC Item using an access token.\"\"\"\n    headers = {\"Authorization\": f\"Bearer {access_token}\"}\n\n    session = requests.Session()\n    session.headers.update(headers)\n    response = session.get(get_asset_href(item, \"PRODUCT\"), headers=headers, stream=True)\n\n    with open(\"product.zip\", \"wb\") as file:\n        for chunk in response.iter_content(chunk_size=8192):\n            if chunk:\n                file.write(chunk)\n    with zipfile.ZipFile(\"product.zip\", \"r\") as zip_ref:\n        zip_ref.extractall(\".\")\n\n    return os.path.join(os.getcwd(), item.id)\n\n@click.command(\n    short_help=\"Stage-in\",\n    help=\"Stage a Sentinel-2 Level-1C product\",\n)\n@click.option(\n    \"--input-item\",\n    \"item_url\",\n    help=\"Sentinel-2 Level-1C CDSE STAC Item URL\",\n    required=True,\n)\ndef stage(item_url):\n    \"\"\"Stages a Sentinel-2 Level-1C product by downloading and extracting it, then creating a STAC Item.\"\"\"\n\n    logger.info(f\"Staging {item_url}\")\n    item = pystac.read_file(item_url)\n\n    access_token = os.environ.get(\"CDSE_ACCESS_TOKEN\")\n    if not access_token:\n        logger.error(\"CDSE_ACCESS_TOKEN environment variable is not set.\")\n        return\n\n    logger.info(\"Downloading and extracting file\")\n    staged_s2 = download_and_extract_file(item, access_token)\n\n    logger.info(\"Creating STAC Item\")\n    s2_item = create_item(\n        granule_href=staged_s2,\n    )\n\n    item_path = os.path.join(\".\", f\"{s2_item.id}.json\")\n    s2_item.set_self_href(item_path)\n\n    s2_item.save_object(include_self_link=False, dest_href=item_path)\n\n    logger.info(\"Creating STAC Catalog\")\n    cat = pystac.Catalog(\n        id=\"catalog\",\n        description=f\"catalog with staged {s2_item.id}\",\n        title=f\"catalog with staged {s2_item.id}\",\n    )\n    s2_item.make_asset_hrefs_relative()\n    cat.add_item(s2_item)\n\n    cat.normalize_hrefs(\"./\")\n    cat.save(catalog_type=pystac.CatalogType.SELF_CONTAINED)\n\n    logger.info(\"Done!\")\n\nif __name__ == \"__main__\":\n    stage()\n</code></pre>"},{"location":"containers/inference/","title":"Inference","text":""},{"location":"containers/inference/#goal","title":"Goal","text":"<ul> <li>Build the container image</li> <li>Run the tile based classification inference in the container image tagged <code>localhost/inference:latest</code>.</li> </ul>"},{"location":"containers/inference/#lab","title":"Lab","text":"<p>This step has a dedicated lab available at <code>/workspace/inference-eoap/practice-labs/Container.ipynb</code></p>"},{"location":"containers/inference/#the-container-recipe","title":"The container recipe","text":"<p>The  tile based classification inference has a recipe to build the container image.</p> <p>The <code>inference</code> step container image recipe is:</p> inference/Dockerfile<pre><code>\n</code></pre>"},{"location":"containers/inference/#building-the-container","title":"Building the container","text":"<p>Build the container images with:</p> terminal<pre><code>export WORKSPACE=/workspace/inference-eoap\n\ncommand -v podman &gt;/dev/null 2&gt;&amp;1 &amp;&amp; { \n\n    podman build --format docker -t localhost/inference:latest ${WORKSPACE}/tile-based-classification/command-line-tools/inference\n\n} || command -v docker &gt;/dev/null 2&gt;&amp;1 &amp;&amp; { \n\n    docker build -t localhost/inference:latest ${WORKSPACE}/tile-based-classification/command-line-tools/inference\n}\n</code></pre>"},{"location":"containers/inference/#expected-outcome","title":"Expected outcome","text":"<p>The local container registry lists the built images:</p> <pre><code>(base) jovyan@coder-mrossi:~/runs$ podman images | grep localhost\nlocalhost/inference  latest      534f3f10c06e  11 minutes ago  530 MB\n</code></pre>"},{"location":"containers/inference/#how-to-run-a-step-in-a-container","title":"How to run a step in a container","text":"<p>We'll use <code>podman</code> container engine (<code>docker</code> is also fine).</p> <p>The command to run the <code>inference</code> step in the container is:</p> <pre><code>WORKSPACE=/workspace/inference-eoap\nRUNTIME=${WORKSPACE}/runs\nmkdir -p ${RUNTIME}\ncd ${RUNTIME}\n\n# check if the results.json file exists\nif [ ! -f ${WORKSPACE}/runs/results.json ]; then\n    echo \"results.json file not found, run the stage-and-cog.cwl workflow first.\"\n    exit 1\nfi\n\npodman run \\\n    -i \\\n    --userns=keep-id \\\n    --mount=type=bind,source=/workspace/inference-eoap/runs,target=/runs \\\n    --workdir=/runs \\\n    --read-only=true \\\n    --user=1001:100 \\\n    --rm \\\n    --env=HOME=/runs \\\n    --env=PYTHONPATH=/app \\\n    localhost/inference:latest \\\n    python \\\n    -m \\\n    app \\\n    --input-item \\\n    $( cat ${WORKSPACE}/runs/results.json | jq -r .stac_catalog.path )\n</code></pre> <p>Let's break down what this command does:</p> <ul> <li><code>podman run</code>: This is the command to run a container.</li> <li><code>-i</code>: This flag makes the container interactive, allowing you to interact with it via the terminal.</li> <li><code>--userns=keep-id</code>: It instructs <code>podman</code> to keep the user namespace ID.</li> <li><code>--mount=type=bind,source=/workspace/runs,target=/runs</code>: This option mounts a directory from the host system to the container. In this case, it mounts the <code>/workspace/runs</code> directory on the host to the /runs directory inside the container.</li> <li><code>--workdir=/runs</code>: Sets the working directory inside the container to <code>/runs</code>.</li> <li><code>--read-only=true</code>: Makes the file system inside the container read-only, meaning you can't write or modify files inside the container.</li> <li><code>--user=1001:100</code>: Specifies the user and group IDs to be used within the container.</li> <li><code>--rm</code>: This flag tells podman to remove the container after it has finished running.</li> <li><code>--env=HOME=/runs</code>: Sets the <code>HOME</code> environment variable inside the container to <code>/runs</code>.</li> <li><code>--env=PYTHONPATH=/app</code>: Sets the <code>PYTHONPATH</code> environment variable inside the container to <code>/app</code>.</li> <li><code>localhost/inference:latest</code>: This is the name of the container image that you want to run. It's pulling the image from the local container registry with the name \"inference\" and the \"latest\" tag.</li> <li><code>python -m app</code>: This is the command to run inside the container. It runs a Python module named \"app\".</li> <li><code>--input-item ...</code>: Specifies the path to the folder where there is a <code>catalog.json</code> file.</li> </ul>"},{"location":"containers/inference/#expected-outcome_1","title":"Expected outcome","text":"<p>The folder <code>/workspace/inference-eoap/runs</code> contains: </p> <pre><code>(base) jovyan@jupyter-mrossi--training:~/inference-eoap$ tree runs/\nruns\n\u251c\u2500\u2500 S2A_T33TVM_20240125T100359_L1C-classification\n\u2502   \u251c\u2500\u2500 S2A_T33TVM_20240125T100359_L1C-classification.json\n\u2502   \u2514\u2500\u2500 classification.tif\n\u251c\u2500\u2500 catalog.json\n\u251c\u2500\u2500 results.json\n\u2514\u2500\u2500 ydmns4od\n    \u251c\u2500\u2500 S2A_T33TVM_20240125T100359_L1C\n    \u2502   \u251c\u2500\u2500 S2A_T33TVM_20240125T100359_L1C.json\n    \u2502   \u251c\u2500\u2500 blue.tif\n    \u2502   \u251c\u2500\u2500 cirrus.tif\n    \u2502   \u251c\u2500\u2500 coastal.tif\n    \u2502   \u251c\u2500\u2500 green.tif\n    \u2502   \u251c\u2500\u2500 nir.tif\n    \u2502   \u251c\u2500\u2500 nir08.tif\n    \u2502   \u251c\u2500\u2500 nir09.tif\n    \u2502   \u251c\u2500\u2500 red.tif\n    \u2502   \u251c\u2500\u2500 rededge1.tif\n    \u2502   \u251c\u2500\u2500 rededge2.tif\n    \u2502   \u251c\u2500\u2500 rededge3.tif\n    \u2502   \u251c\u2500\u2500 swir16.tif\n    \u2502   \u2514\u2500\u2500 swir22.tif\n    \u2514\u2500\u2500 catalog.json\n\n3 directories, 19 files\n</code></pre>"},{"location":"containers/scope/","title":"Scope","text":"<p>When developers package and EO, they are in fact packaging their own software, written in a specific programming language, as a containerized application (or a set of containerized applications), to be described as an EO Application Package using the Common Workflow Language as described in the OGC proposed best practices.</p> <p>To achieve this, developers follow the steps described below.</p> <ul> <li>Prepare one or more container images containing the execution dependencies of the software.</li> <li>Prepare the CWL CommandLineTool document(s) wrapping the command line tool available container(s).</li> <li>Prepare the CWL Workflow orchestrating CWL CommandLineTool document(s) wrapping the command line tool available container(s).</li> <li>Test the application package in one or more execution scenarios.</li> </ul>"},{"location":"cwl-cli/inference/","title":"Inference","text":""},{"location":"cwl-cli/inference/#goal","title":"Goal","text":"<p>Wrap the inference Python command line tool as a Common Workflow Language <code>CommandLineTool</code> and execute it with a CWL runner.</p>"},{"location":"cwl-cli/inference/#lab","title":"Lab","text":"<p>This step has a dedicated lab available at <code>/workspace/inference-eoap/practice-labs/CommandLineTool.ipynb</code></p>"},{"location":"cwl-cli/inference/#how-to-wrap-a-step-as-a-cwl-commandlinetool","title":"How to wrap a step as a CWL CommandLineTool","text":"<p>The CWL document below shows the inference Python command line tool step wrapped as a CWL CommandLineTool:</p> cwl-cli/inference<pre><code>cwlVersion: v1.0\n\nclass: CommandLineTool\nid: inference\nrequirements:\n  InlineJavascriptRequirement: {}\n  EnvVarRequirement:\n    envDef:\n      PATH: /usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin\n      PYTHONPATH: /app\n  ResourceRequirement:\n    coresMax: 2\n    ramMax: 4096\nhints:\n  DockerRequirement:\n    dockerPull: localhost/inference:latest\nbaseCommand: [\"python\", \"-m\", \"app\"]\narguments: []\ninputs:\n  input-item:\n    type: Directory\n    inputBinding:\n      prefix: --input-item\noutputs:\n  stac_catalog:\n    outputBinding:\n      glob: .\n    type: Directory\n</code></pre> <p>Let's break down the key components of this CWL document:</p> <ul> <li><code>cwlVersion: v1.0</code>: Specifies the version of the CWL specification that this document follows.</li> <li><code>class: CommandLineTool</code>: Indicates that this CWL document defines a command-line tool.</li> <li><code>id: crop</code>: Provides a unique identifier for this tool, which can be used to reference it in workflows.</li> <li><code>requirements</code>: Specifies the requirements and dependencies of the tool. In this case, it defines the following:<ul> <li><code>InlineJavascriptRequirement</code>: This requirement allows the use of inline JavaScript expressions in the tool.</li> <li><code>EnvVarRequirement</code>: It sets environment variables. In this case, it sets the <code>PYTHONPATH</code> environment variable to \"/app.\"</li> <li><code>ResourceRequirement</code>: Specifies resource requirements for running the tool, including the maximum number of CPU cores and maximum RAM.</li> <li><code>DockerRequirement</code>: This requirement specifies the Docker container to be used. It indicates that the tool should be executed in a Docker container with the image <code>localhost/crop:latest</code>.</li> </ul> </li> <li><code>baseCommand</code>: Defines the base command to be executed in the container. In this case, it's running a Python module called \"app\" with the command <code>python -m app</code>.</li> <li><code>arguments</code>: This section is empty, meaning there are no additional command-line arguments specified here. The tool is expected to receive its arguments via the input parameters.</li> <li><code>inputs</code>: Describes the input parameters for the tool, including their types and how they are bound to command-line arguments. The tool expects the following inputs:<ul> <li><code>--input-item</code>: the path to the folder where a Sentinel-2 Level-1C has been staged and converted to COG.</li> </ul> </li> <li><code>outputs</code>: Specifies the tool's output. It defines an output parameter named <code>stac_catalog</code>, which is of type <code>Directory</code>. The outputBinding section specifies that the tool is expected to produce one or more files (glob: .) as output.</li> </ul>"},{"location":"cwl-cli/inference/#steps","title":"Steps","text":"<p>Run the CWL document using the <code>cwltool</code> CWL runner to execute the tile based classification inference:</p> terminal<pre><code>export WORKSPACE=/workspace/inference-eoap\n\n# check if the results.json file exists\nif [ ! -f ${WORKSPACE}/runs/results.json ]; then\n    echo \"results.json file not found, run the stage-and-cog.cwl workflow first.\"\n    exit 1\nfi\n\ncommand -v podman &gt;/dev/null 2&gt;&amp;1 &amp;&amp; { \n    flag=\"--podman\"\n}\n\ncwltool ${flag} \\\n    --outdir ${WORKSPACE}/runs \\\n    ${WORKSPACE}/cwl-cli/inference.cwl \\\n    $( cat ${WORKSPACE}/runs/results.json | jq -r .stac_catalog.path )\n</code></pre>"},{"location":"cwl-cli/inference/#expected-outcome","title":"Expected outcome","text":"<p>The folder <code>/workspace/inference-eoap/runs</code> contains: </p> <pre><code>(base) jovyan@jupyter-fbrito--training:~/inference-eoap$ tree runs\nruns\n\u251c\u2500\u2500 am8yu9it\n\u2502   \u251c\u2500\u2500 S2A_T33TVM_20240125T100359_L1C-classification\n\u2502   \u2502   \u251c\u2500\u2500 S2A_T33TVM_20240125T100359_L1C-classification.json\n\u2502   \u2502   \u2514\u2500\u2500 classification.tif\n\u2502   \u2514\u2500\u2500 catalog.json\n\u251c\u2500\u2500 results.json\n\u2514\u2500\u2500 ydmns4od\n    \u251c\u2500\u2500 S2A_T33TVM_20240125T100359_L1C\n    \u2502   \u251c\u2500\u2500 S2A_T33TVM_20240125T100359_L1C.json\n    \u2502   \u251c\u2500\u2500 blue.tif\n    \u2502   \u251c\u2500\u2500 cirrus.tif\n    \u2502   \u251c\u2500\u2500 coastal.tif\n    \u2502   \u251c\u2500\u2500 green.tif\n    \u2502   \u251c\u2500\u2500 nir.tif\n    \u2502   \u251c\u2500\u2500 nir08.tif\n    \u2502   \u251c\u2500\u2500 nir09.tif\n    \u2502   \u251c\u2500\u2500 red.tif\n    \u2502   \u251c\u2500\u2500 rededge1.tif\n    \u2502   \u251c\u2500\u2500 rededge2.tif\n    \u2502   \u251c\u2500\u2500 rededge3.tif\n    \u2502   \u251c\u2500\u2500 swir16.tif\n    \u2502   \u2514\u2500\u2500 swir22.tif\n    \u2514\u2500\u2500 catalog.json\n\n4 directories, 19 files\n</code></pre>"},{"location":"cwl-cli/scope/","title":"Scope","text":"<p>When developers package and EO, they are in fact packaging their own software, written in a specific programming language, as a containerized application (or a set of containerized applications), to be described as an EO Application Package using the Common Workflow Language as described in the OGC proposed best practices.</p> <p>To achieve this, developers follow the steps described below.</p> <ul> <li>Prepare one or more container images containing the execution dependencies of the software.</li> <li>Prepare the CWL CommandLineTool document(s) wrapping the command line tool available in container(s).</li> <li>Prepare the CWL Workflow orchestrating CWL CommandLineTool document(s) wrapping the command line tool available container(s).</li> <li>Test the application package in one or more execution scenarios.</li> </ul> <p>This section shows how to do the step:</p> <ul> <li>Prepare the CWL CommandLineTool document wrapping the command line tool available container.</li> </ul>"},{"location":"cwl-workflow/scope/","title":"Scope","text":"<p>When developers package and EO, they are in fact packaging their own software, written in a specific programming language, as a containerized application (or a set of containerized applications), to be described as an EO Application Package using the Common Workflow Language as described in the OGC proposed best practices.</p> <p>To achieve this, developers follow the steps described below.</p> <ul> <li>Prepare one or more container images containing the execution dependencies of the software.</li> <li>Prepare the CWL CommandLineTool document(s) wrapping the command line tool available in container(s).</li> <li>Prepare the CWL Workflow orchestrating CWL CommandLineTool document(s) wrapping the command line tool available container(s).</li> <li>Test the application package in one or more execution scenarios.</li> </ul> <p>This section shows how to do the step:</p> <ul> <li>Prepare the CWL Workflow orchestrating CWL CommandLineTool document(s) wrapping the command line tool available container(s).</li> </ul>"},{"location":"cwl-workflow/scope/#orchestrating-cwl-commandlinetools","title":"Orchestrating CWL CommandLineTools","text":"<p>The CWL <code>CommandLineTool</code>s wrapping the inference command-line tools had a single CWL class.</p> <p>An Application Package must include at least one CWL <code>Workflow</code> class orchestrating the CWL <code>CommandLineTool</code> above.</p> <p>We will need a CWL document with a list of process objects: a <code>Workflow</code> class and CWL <code>CommandLineTool</code> wrapping the Python command line tool. </p> <p>A <code>$graph</code> document does not have a process object at the root. Instead there is a <code>$graph</code> field which consists of a list of process objects.</p> <p>Each process object must have an <code>id</code> field: </p> <pre><code>cwlVersion=1.0\n\n$graph:\n- class: Workflow\n  id: main\n  ...\n\n- class: CommandLineTool\n  id: inference\n  ...\n</code></pre> <p>Workflow run fields cross-reference other processes in the document <code>$graph</code> using the <code>id</code> of the process object:</p> <pre><code>cwlVersion=1.0\n\n$graph:\n- class: Workflow\n  id: main\n  steps:\n    node_inference:\n      run: \"#inference\"\n      ...\n  ...\n\n- class: CommandLineTool\n  id: inference\n  ...\n</code></pre> <p>We propose the Workflow <code>tile-based-classification.cwl</code> reading a staged and converted to COG Sentinel-2 Level-1C acquisition orchestrating the inference Python command line tool.</p>"},{"location":"cwl-workflow/stage-and-cog/","title":"Stage and cog","text":""},{"location":"cwl-workflow/stage-and-cog/#goal","title":"Goal","text":"<p>Run the stage-and-cog.cwl CWL Workflow that that stages a Sentinel-2 Level-1C from the CDSE and converts/resamples its assets to COG.</p>"},{"location":"cwl-workflow/stage-and-cog/#lab","title":"Lab","text":"<p>This step has a dedicated lab available at <code>/workspace/inference-eoap/practice-labs/Application steps/01 - Stage-and-cog.ipynb</code></p>"},{"location":"cwl-workflow/stage-and-cog/#dependencies","title":"Dependencies","text":"<p>This steps requires generating a CDSE access token with the Python script and your own CDSE credentials: </p> bin/get-bearer-token<pre><code>#!/usr/bin/env python3\n\nimport click\nimport requests\n\ndef get_access_token(username: str, password: str) -&gt; str:\n    data = {\n        \"client_id\": \"cdse-public\",\n        \"username\": username,\n        \"password\": password,\n        \"grant_type\": \"password\",\n    }\n    try:\n        r = requests.post(\n            \"https://identity.dataspace.copernicus.eu/auth/realms/CDSE/protocol/openid-connect/token\",\n            data=data,\n        )\n        r.raise_for_status()\n    except Exception as e:\n        raise Exception(\n            f\"Access token creation failed. Response from the server was: {r.json()}\"\n        )\n    return r.json()[\"access_token\"]\n\n@click.command(\n    short_help=\"Get bearer token\",\n    help=\"Get a bearer token for the Copernicus Data Space Ecosystem \",\n)\n@click.option(\n    \"--username\",\n    help=\"Username for the Copernicus Data Space Ecosystem\",\n    required=True,\n)\n@click.option(\n    \"--password\",\n    help=\"Password for the Copernicus Data Space Ecosystem\",\n    required=True,\n)\ndef get_bearer_token(username: str, password: str) -&gt; str:\n\n    return print(get_access_token(username, password))\n\nif __name__ == \"__main__\":\n    get_bearer_token()\n</code></pre>"},{"location":"cwl-workflow/stage-and-cog/#lab_1","title":"Lab","text":"<p>This step has a dedicated lab available at <code>/workspace/inference-eoap/practice-labs/Application steps/01 - Stage-and-cog.ipynb</code></p>"},{"location":"cwl-workflow/stage-and-cog/#step-1-run-the-stage-and-cogcwl_-cwl-workflow","title":"Step 1 - Run the stage-and-cog.cwl_ CWL Workflow","text":"<p>Use <code>cwltool</code> to run the stage-and-cog.cwl CWL Workflow with a Sentinel-2 Level-1C acquisition reference</p> <p>The CWL Workflow is shown below and the lines highlighted chain the <code>stage-in</code> and <code>conversion</code> to COG steps:</p> stage-and-cog.cwl<pre><code>cwlVersion: v1.0\n$namespaces:\n  s: https://schema.org/\ns:softwareVersion: 1.0.0\nschemas:\n  - http://schema.org/version/9.0/schemaorg-current-http.rdf\n$graph:\n  - class: Workflow\n    id: main\n    label: Stage-in and cog-ify a Sentinel-2 L1C acquisition\n    doc: Stage-in and cog-ify a Sentinel-2 L1C acquisition\n    requirements: {}\n    inputs:\n      item:\n        doc: Reference to a STAC item\n        label: STAC item reference\n        type: string\n      access_token:\n        doc: CDSE bearer token\n        label: CDSE bearer token\n        type: string\n    outputs:\n      - id: stac_catalog\n        outputSource:\n          - node_sen2cog/stac_catalog\n        type: Directory\n    steps:\n      node_stage_in:\n        run: \"#stage-in\"\n        in:\n          item: item\n          access_token: access_token\n        out:\n          - staged\n      node_sen2cog:\n        run: \"#sen2cog\"\n        in:\n          staged:\n            source: node_stage_in/staged\n        out:\n          - stac_catalog\n\n  - class: CommandLineTool\n    id: stage-in\n    requirements:\n      InlineJavascriptRequirement: {}\n      EnvVarRequirement:\n        envDef:\n          PATH: /usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin\n          PYTHONPATH: /app\n          CDSE_ACCES_TOKEN: $(inputs.access_token)\n      ResourceRequirement:\n        coresMax: 1\n        ramMax: 1024\n    hints:\n      DockerRequirement:\n        dockerPull: localhost/stage-in:latest\n    baseCommand: [\"python\", \"-m\", \"app\"]\n    arguments: []\n    inputs:\n      item:\n        type: string\n        inputBinding:\n          prefix: --input-item\n      access_token:\n        type: string\n    outputs:\n      staged:\n        outputBinding:\n          glob: .\n        type: Directory\n  - class: CommandLineTool\n    id: sen2cog\n    requirements:\n      InlineJavascriptRequirement: {}\n      EnvVarRequirement:\n        envDef:\n          PATH: /usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin\n          PYTHONPATH: /app\n      ResourceRequirement:\n        coresMax: 2\n        ramMax: 4096\n    hints:\n      DockerRequirement:\n        dockerPull: docker.io/library/sen2cog:latest\n    baseCommand: [\"python\", \"-m\", \"app\"]\n    arguments: []\n    inputs:\n      staged:\n        type: Directory\n        inputBinding:\n          prefix: --input-catalog\n    outputs:\n      stac_catalog:\n        outputBinding:\n          glob: .\n        type: Directory\n</code></pre> <p>To run this CWL document run the script below to:</p> <ul> <li>provide your CDSE username and password to generate and access token</li> <li>Use <code>cwltool</code> to run stage-and-cog.cwl CWL description  </li> </ul> terminal<pre><code>version=\"1.0.0\"\n\nexport WORKSPACE=/workspace/inference-eoap\n\nexport PATH=${WORKSPACE}/bin:$PATH\n\nread -p \"Enter the CDSE username: \" username\nread -sp \"Enter the CDSE password: \" password\n\nBEARER_TOKEN=$( get-bearer-token ${username} ${password} )\n\ncwltool \\\n    --podman \\\n    --outdir ${WORKSPACE}/runs \\\n    https://github.com/eoap/inference-eoap/releases/download/1.0.0/stage-and-cog.1.0.0.cwl \\\n    --access_token ${BEARER_TOKEN} \\\n    --item \"https://catalogue.dataspace.copernicus.eu/stac/collections/SENTINEL-2/items/S2A_MSIL1C_20240125T100311_N0510_R122_T33TVM_20240125T104959.SAFE\" &gt; ${WORKSPACE}/runs/results.json\n</code></pre>"},{"location":"cwl-workflow/stage-and-cog/#expected-outcome","title":"Expected outcome","text":"<p>The folder <code>/workspace/inference-eoap/runs</code> contains: </p> <pre><code>(base) jovyan@jupyter-fbrito--training:~/inference-eoap$ tree runs\nruns\n\u251c\u2500\u2500 results.json\n\u2514\u2500\u2500 ydmns4od\n    \u251c\u2500\u2500 S2A_T33TVM_20240125T100359_L1C\n    \u2502   \u251c\u2500\u2500 S2A_T33TVM_20240125T100359_L1C.json\n    \u2502   \u251c\u2500\u2500 blue.tif\n    \u2502   \u251c\u2500\u2500 cirrus.tif\n    \u2502   \u251c\u2500\u2500 coastal.tif\n    \u2502   \u251c\u2500\u2500 green.tif\n    \u2502   \u251c\u2500\u2500 nir.tif\n    \u2502   \u251c\u2500\u2500 nir08.tif\n    \u2502   \u251c\u2500\u2500 nir09.tif\n    \u2502   \u251c\u2500\u2500 red.tif\n    \u2502   \u251c\u2500\u2500 rededge1.tif\n    \u2502   \u251c\u2500\u2500 rededge2.tif\n    \u2502   \u251c\u2500\u2500 rededge3.tif\n    \u2502   \u251c\u2500\u2500 swir16.tif\n    \u2502   \u2514\u2500\u2500 swir22.tif\n    \u2514\u2500\u2500 catalog.json\n\n2 directories, 16 files\n</code></pre>"},{"location":"cwl-workflow/tile-based-classification/","title":"Tile Based Classification","text":""},{"location":"cwl-workflow/tile-based-classification/#goal","title":"Goal","text":"<p>Wrap the CommandLineTool with a CWL Workflow</p>"},{"location":"cwl-workflow/tile-based-classification/#lab","title":"Lab","text":"<p>This step has a dedicated lab available at <code>/workspace/inference-eoap/practice-labs/Workflow.ipynb</code></p>"},{"location":"cwl-workflow/tile-based-classification/#how-to-wrap-a-cwl-commandlinetool-with-a-cwl-workflow","title":"How to wrap a CWL CommandLineTool with a CWL Workflow","text":"<p>The Cloud native Workflow orchestrates the wrapped Python application command line tool as a CWL <code>CommandLineTool</code> step with input parameters:</p> <ul> <li>a staged and converted to COG Sentinel-2 Level-1C acquisition </li> </ul> graph TB A[STAC Catalog] A --&gt; B((\"Inference\")); B --&gt; C[STAC Catalog] <p>The CWL Workflow is shown below and the lines highlighted chain the inference step:</p> tile-based-classification.cwl<pre><code>cwlVersion: v1.0\n$namespaces:\n  s: https://schema.org/\ns:softwareVersion: 1.0.0\nschemas:\n  - http://schema.org/version/9.0/schemaorg-current-http.rdf\n$graph:\n  - class: Workflow\n    id: main\n    label: Sentinel-2 Level-1C Tile Based Classification\n    doc: Sentinel-2 Level-1C Tile Based Classification based on EUROSAT dataset\n    requirements: {}\n    inputs:\n      item:\n        doc: Reference to a STAC item\n        label: STAC item reference\n        type: Directory\n    outputs:\n      - id: stac_catalog\n        outputSource:\n          - node_inference/stac_catalog\n        type: Directory\n    steps:\n      node_inference:\n        run: \"#inference\"\n        in:\n          input-item: item\n        out:\n          - stac_catalog\n  - class: CommandLineTool\n    id: inference\n    requirements:\n      InlineJavascriptRequirement: {}\n      EnvVarRequirement:\n        envDef:\n          PATH: /usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin\n          PYTHONPATH: /app\n      ResourceRequirement:\n        coresMax: 2\n        ramMax: 4096\n    hints:\n      DockerRequirement:\n        dockerPull: localhost/inference:latest\n    baseCommand: [\"python\", \"-m\", \"app\"]\n    arguments: []\n    inputs:\n      input-item:\n        type: Directory\n        inputBinding:\n          prefix: --input-item\n    outputs:\n      stac_catalog:\n        outputBinding:\n          glob: .\n        type: Directory\n</code></pre> <p>To run this CWL document, one does:</p> terminal<pre><code>export WORKSPACE=/workspace/inference-eoap\n\ncommand -v podman &gt;/dev/null 2&gt;&amp;1 &amp;&amp; { \n    flag=\"--podman\"\n}\n\n# check if the results.json file exists\nif [ ! -f ${WORKSPACE}/runs/results.json ]; then\n    echo \"results.json file not found, run the stage-and-cog.cwl workflow first.\"\n    exit 1\nfi\n\n\ncwltool ${flag} \\\n    --outdir ${WORKSPACE}/runs \\\n    ${WORKSPACE}/cwl-workflow/tile-based-classification.cwl.cwl \\\n    --input-item $( cat ${WORKSPACE}/runs/results.json | jq -r .stac_catalog.path )\n</code></pre>"},{"location":"cwl-workflow/tile-based-classification/#expected-outcome","title":"Expected outcome","text":"<p>The folder <code>/workspace/inference-eoap/runs</code> contains: </p> <pre><code>(base) jovyan@jupyter-fbrito--training:~/inference-eoap$ tree runs\nruns\n\u251c\u2500\u2500 results.json\n\u2514\u2500\u2500 ydmns4od\n    \u251c\u2500\u2500 S2A_T33TVM_20240125T100359_L1C\n    \u2502   \u251c\u2500\u2500 S2A_T33TVM_20240125T100359_L1C.json\n    \u2502   \u251c\u2500\u2500 blue.tif\n    \u2502   \u251c\u2500\u2500 cirrus.tif\n    \u2502   \u251c\u2500\u2500 coastal.tif\n    \u2502   \u251c\u2500\u2500 green.tif\n    \u2502   \u251c\u2500\u2500 nir.tif\n    \u2502   \u251c\u2500\u2500 nir08.tif\n    \u2502   \u251c\u2500\u2500 nir09.tif\n    \u2502   \u251c\u2500\u2500 red.tif\n    \u2502   \u251c\u2500\u2500 rededge1.tif\n    \u2502   \u251c\u2500\u2500 rededge2.tif\n    \u2502   \u251c\u2500\u2500 rededge3.tif\n    \u2502   \u251c\u2500\u2500 swir16.tif\n    \u2502   \u2514\u2500\u2500 swir22.tif\n    \u2514\u2500\u2500 catalog.json\n\n2 directories, 16 files\n</code></pre>"},{"location":"exec/scope/","title":"Scope","text":"<p>When developers package and EO, they are in fact packaging their own software, written in a specific programming language, as a containerized application (or a set of containerized applications), to be described as an EO Application Package using the Common Workflow Language as described in the OGC proposed best practices.</p> <p>To achieve this, developers follow the steps described below.</p> <ul> <li>Prepare one or more container images containing the execution dependencies of the software.</li> <li>Prepare the CWL CommandLineTool document(s) wrapping the command line tool available in container(s).</li> <li>Prepare the CWL Workflow orchestrating CWL CommandLineTool document(s) wrapping the command line tool available container(s).</li> <li>Test the application package in one or more execution scenarios.</li> </ul> <p>This page covers the step:</p> <p>Test the application package in one or more execution scenarios</p>"},{"location":"exec/tile-based-classification/","title":"Tile Based Classification","text":""},{"location":"exec/tile-based-classification/#goal","title":"Goal","text":"<p>Run the <code>tile-based-classification.1.0.0.cwl</code> released application package using <code>cwltool</code>.</p>"},{"location":"exec/tile-based-classification/#lab","title":"Lab","text":"<p>This step has a dedicated lab available at <code>/workspace/inference-eoap/practice-labs/Execution-scenario.ipynb</code></p>"},{"location":"exec/tile-based-classification/#step-1-configure-the-workspace","title":"Step 1 - Configure the workspace","text":"<p>The results produced will be available in the local folder <code>/workspace/inference-eoap/runs</code></p> terminal<pre><code>export WORKSPACE=/workspace/inference-eoap\nexport RUNTIME=${WORKSPACE}/runs\nmkdir -p ${RUNTIME}\ncd ${RUNTIME}\n</code></pre>"},{"location":"exec/tile-based-classification/#step-2-download-the-released-application-package","title":"Step 2 - Download the released Application package","text":"scripts/download-app-inference.sh<pre><code>version=\"1.0.0\"\n\nexport WORKSPACE=/workspace/inference-eoap\n\nwget \\\n    -O ${WORKSPACE}/runs/tile-based-classification.${version}.cwl \\\n    https://github.com/eoap/inference-eoap/releases/download/1.0.0/tile-based-classification.${version}.cwl\n</code></pre>"},{"location":"exec/tile-based-classification/#step-3-execute-the-application-package","title":"Step 3 - Execute the Application Package","text":"scripts/exec-app-inference.sh<pre><code>version=\"1.0.0\"\n\nexport WORKSPACE=/workspace/inference-eoap\n\n# check if the results.json file exists\nif [ ! -f ${WORKSPACE}/runs/results.json ]; then\n    echo \"results.json file not found, run the stage-and-cog.cwl workflow first.\"\n    exit 1\nfi\n\ncwltool \\\n    --podman \\\n    --outdir ${WORKSPACE}/runs \\\n    ${WORKSPACE}/runs/tile-based-classification.${version}.cwl \\\n    --input-item $( cat ${WORKSPACE}/runs/results.json | jq -r .stac_catalog.path )\n</code></pre>"},{"location":"exec/tile-based-classification/#expected-outcome","title":"Expected outcome","text":"<p>The folder <code>/workspace/inference-eoap/runs</code> contains: </p> <pre><code>(base) jovyan@jupyter-fbrito--training:~/inference-eoap$ tree runs\nruns\nTODO\n2 directories, 5 files\n</code></pre>"},{"location":"python-env/inference/","title":"Running the step","text":""},{"location":"python-env/inference/#goal","title":"Goal","text":"<p>Run the command line tool in a Python virtual environment.</p>"},{"location":"python-env/inference/#dependencies","title":"Dependencies","text":"<p>This step depends on the execution of the <code>stage-and-cog.cwl</code> workflow that stages a Sentinel-2 Level-1C from the CDSE and converts/resamples its assets to COG.</p>"},{"location":"python-env/inference/#lab","title":"Lab","text":"<p>This step has a dedicated lab available at <code>/workspace/inference-eoap/practice-labs/Application steps/02 - Inference.ipynb</code></p>"},{"location":"python-env/inference/#step-1-configure-the-workspace","title":"Step 1 - Configure the workspace","text":"<p>The results produced will be available in the local folder <code>/workspace/inference-eoap/runs</code></p> terminal<pre><code>export WORKSPACE=/workspace/inference-eoap\nexport RUNTIME=${WORKSPACE}/runs\nmkdir -p ${RUNTIME}\ncd ${RUNTIME}\n</code></pre>"},{"location":"python-env/inference/#step-2-create-the-python-virtual-environment","title":"Step 2 - Create the Python virtual environment","text":"<p>The required Python modules are installed using <code>pip</code>:</p> terminal<pre><code>python3 -m venv env_inference\nsource env_inference/bin/activate\npip install --no-cache-dir pystac==1.9.0 click loguru requests numpy rasterio onnx onnxruntime rio-stac\n</code></pre>"},{"location":"python-env/inference/#step-3-run-the-inference","title":"Step 3 - Run the inference","text":"<p>The command line tool is invoked with:</p> terminal<pre><code>WORKSPACE=/workspace/inference-eoap\nRUNTIME=${WORKSPACE}/runs\nmkdir -p ${RUNTIME}\ncd ${RUNTIME}\n\n# check if the results.json file exists\nif [ ! -f ${WORKSPACE}/runs/results.json ]; then\n    echo \"results.json file not found, run the stage-and-cog.cwl workflow first.\"\n    exit 1\nfi\n\npython \\\n    ${WORKSPACE}/tile-based-classification/command-line-tools/inference/app.py \\\n    --input-item $( cat ${WORKSPACE}/runs/results.json | jq -r .stac_catalog.path )\n</code></pre>"},{"location":"python-env/inference/#step-4-clean-up","title":"Step 4 - Clean-up","text":"<p>The Python virtual environment is no longer needed.</p> terminal<pre><code>deactivate\nrm -fr env_inference\n</code></pre>"},{"location":"python-env/inference/#expected-outcome","title":"Expected outcome","text":"<p>The folder <code>/workspace/inference-eoap/runs</code> contains: </p> <pre><code>runs\n\u251c\u2500\u2500 S2A_T33TVM_20240125T100359_L1C-classification\n\u2502   \u251c\u2500\u2500 S2A_T33TVM_20240125T100359_L1C-classification.json\n\u2502   \u2514\u2500\u2500 classification.tif\n\u251c\u2500\u2500 catalog.json\n\u251c\u2500\u2500 results.json\n\u2514\u2500\u2500 ydmns4od\n    \u251c\u2500\u2500 S2A_T33TVM_20240125T100359_L1C\n    \u2502   \u251c\u2500\u2500 S2A_T33TVM_20240125T100359_L1C.json\n    \u2502   \u251c\u2500\u2500 blue.tif\n    \u2502   \u251c\u2500\u2500 cirrus.tif\n    \u2502   \u251c\u2500\u2500 coastal.tif\n    \u2502   \u251c\u2500\u2500 green.tif\n    \u2502   \u251c\u2500\u2500 nir.tif\n    \u2502   \u251c\u2500\u2500 nir08.tif\n    \u2502   \u251c\u2500\u2500 nir09.tif\n    \u2502   \u251c\u2500\u2500 red.tif\n    \u2502   \u251c\u2500\u2500 rededge1.tif\n    \u2502   \u251c\u2500\u2500 rededge2.tif\n    \u2502   \u251c\u2500\u2500 rededge3.tif\n    \u2502   \u251c\u2500\u2500 swir16.tif\n    \u2502   \u2514\u2500\u2500 swir22.tif\n    \u2514\u2500\u2500 catalog.json\n\n3 directories, 19 files\n</code></pre>"},{"location":"release/ci/","title":"Continuous Integration","text":""},{"location":"release/ci/#application-package-software-configuration-management","title":"Application Package Software Configuration Management","text":"<p>The SCM has the task of tracking and controlling changes in the software as a part of the larger cross-disciplinary field of configuration management. </p> <p>SCM practices include revision control and the establishment of baselines.</p> <p>The Application Package code is hosted on a repository publicly accessible (Github, Bitbucket, a GitLab instance, an institutional software forge, etc.) using one of the version control systems supported by (Subversion, Mercurial and Git)</p> <p>The Application Package code include, at the top level of the source code tree, the following files:</p> <ul> <li>README containing a description of the software (name, purpose, pointers to website, documentation, development platform, contact, and support information, \u2026)</li> <li>AUTHORS, a list of all the persons to be credited for the software.</li> <li>LICENSE, the project license terms. For Open Source Licenses, the standard SPDX license names are used. For large software projects and developers, the REUSE (https://reuse.software/) process and tools can be an option to look at.</li> <li>codemeta.json, a linked data metadata file that helps index the source code in the Software Heritage archive and provides an easy way to link to other related research outputs.</li> </ul> <p>The codemeta.json includes metadata information to support the Continuous Integration phase and it is shown below:</p> codemeta.json<pre><code>{\n    \"@context\": \"https://doi.org/10.5063/schema/codemeta-2.0\",\n    \"@type\": \"SoftwareSourceCode\",\n    \"license\": \"https://spdx.org/licenses/CC-BY-NC-SA-4.0\",\n    \"codeRepository\": \"https://github.com/eoap/inference-eoap.git\",\n    \"dateCreated\": \"2023-05-16\",\n    \"datePublished\": \"2023-05-16\",\n    \"dateModified\": \"2023-05-16\",\n    \"name\": \"Tile based classification\",\n    \"version\": \"1.0.0\",\n    \"description\": \"The tile based classification is a software package that allows to classify a Sentinel-2 Level 1C using a pre-trained model.\",\n    \"developmentStatus\": \"active\",\n    \"downloadUrl\": \"https://github.com/eoap/inference-eoap/releases/tag/1.0.0\",\n    \"relatedLink\": [\n        \"https://eoap.github.io/inference-eoap\"\n    ],\n    \"funder\": {\n        \"@type\": \"Organization\",\n        \"name\": \"Terradue\"\n    },\n    \"keywords\": [\n        \"EUROSAT\", \"Sentinel-2\", \"Classification\"\n    ],\n    \"programmingLanguage\": [\n        \"Python\", \"CWL\"\n    ],\n    \"softwareRequirements\": [\n        \"container runtime\",\n        \"cwl runner\"\n    ],\n    \"author\": [\n        {\n            \"@type\": \"Person\",\n            \"givenName\": \"Jane\",\n            \"familyName\": \"Doe\",\n            \"email\": \"jane.doe@acme.earth\",\n            \"affiliation\": {\n                \"@type\": \"Organization\",\n                \"name\": \"ACME\"\n            }\n        },\n        {\n            \"@type\": \"Person\",\n            \"givenName\": \"John\",\n            \"familyName\": \"Doe\",\n            \"email\": \"john.doe@acme.earth\",\n            \"affiliation\": {\n                \"@type\": \"Organization\",\n                \"name\": \"ACME\"\n            }\n        }\n    ]\n}\n</code></pre>"},{"location":"release/ci/#application-package-continuous-integration","title":"Application Package Continuous Integration","text":"<p>A typical Continuous Integration scenario for an Application Package includes the release of the CWL document(s) and publishing the container images to a container registry.</p> <p>This is depicted below: </p> graph TB SCM[(software repository)] SCM -- CWL Workflow --&gt; A SCM -- codemeta.json --&gt; B A(validate CWL Workflow) --&gt; B(extract version) B --&gt; C subgraph Build containers SCM -- Dockerfiles --&gt; C C(build container) --&gt; D(push container)  end D -- push --&gt; CR[(Container Registry)]  D -- container sha256 --&gt; F(\"update Dockerpull/metadata in CWL Workflows\")  F -- push --&gt; AR[(Artifact Registry)] SCM -- codemeta.json --&gt; F <p>Below an example of a GitHub CI configuration implementing the scenario:</p> .github/workflows/build.yaml"},{"location":"release/ci/#artefacts","title":"Artefacts","text":"<p>The released application package is published here: https://github.com/eoap/inference-eoap/releases/tag/1.0.0</p> <p>The container is available at: https://github.com/eoap/inference-eoap/pkgs/container/inference-eoap%2Finference</p>"},{"location":"release/scope/","title":"Scope","text":"<p>Releasing an Application Package targets:</p> <ul> <li> <p>building and pushing the container images to a container registry</p> </li> <li> <p>updating the Application Package to reference these container images </p> </li> <li> <p>pushing the updated Application Package to an artifact repository</p> </li> </ul>"}]}